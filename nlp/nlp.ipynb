{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/dl/blob/master/nlp/nlp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Languaje Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚡ NLP is a very active field at the moment, new huge architectures (Transformers) and training techniques (language modeling on big unsupervised datasets) are providing excellent results improving SOTA by large margin on almost  every task. See for example: https://openai.com/blog/openai-api/. Some applications include:\n",
    "\n",
    "- Language comprehension (virtual assistants such as Siri, Alexa, …) \n",
    "- Machine translation (Google Translate, …)\n",
    "- Text generation (language modeling, summarization, question answering)\n",
    "- Text classification(sentiment analysis, identify hate speech on social media, ...)\n",
    "- Text-to-speech (generate audio from text) and Speech-to-text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate Shakespearean text using a character RNN (*CharRNN*, https://github.com/karpathy/char-rnn). A CharRNN is able to generate new text, one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.051757Z",
     "start_time": "2020-06-17T17:03:25.104757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..........................................................................] 1115394 / 1115394"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shakespeare (2).txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download dataset\n",
    "\n",
    "import wget\n",
    "\n",
    "url = \"https://mymldatasets.s3.eu-de.cloud-object-storage.appdomain.cloud/shakespeare.txt\"\n",
    "wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.082760Z",
     "start_time": "2020-06-17T17:03:26.052758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou',\n",
       " 1115394)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file\n",
    "\n",
    "f = open(\"shakespeare.txt\", \"r\")\n",
    "text = f.read()\n",
    "text[:100], len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to encode every character in the text as an integer. This process is called **tokenization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.112757Z",
     "start_time": "2020-06-17T17:03:26.083758Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Tokenizer(): \n",
    "  def __init__(self):\n",
    "    self.all_characters = string.printable\n",
    "    self.n_characters = len(self.all_characters)\n",
    "  def text_to_seq(self, string):\n",
    "    seq = []\n",
    "    for c in range(len(string)):\n",
    "        seq.append(self.all_characters.index(string[c]))\n",
    "    return seq\n",
    "  def seq_to_text(self, seq):\n",
    "    text = ''\n",
    "    for c in range(len(seq)):\n",
    "        text += self.all_characters[seq[c]]\n",
    "    return text\n",
    "\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.143760Z",
     "start_time": "2020-06-17T17:03:26.113758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.175759Z",
     "start_time": "2020-06-17T17:03:26.144759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.207760Z",
     "start_time": "2020-06-17T17:03:26.176759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 11, 12, 39, 40, 41]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.text_to_seq('abcDEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.238759Z",
     "start_time": "2020-06-17T17:03:26.208760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.seq_to_text([10, 11, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.519760Z",
     "start_time": "2020-06-17T17:03:26.240759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 18, 27, 28, 29, 94, 38, 18, 29, 18]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoded = tokenizer.text_to_seq(text)\n",
    "text_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.551757Z",
     "start_time": "2020-06-17T17:03:26.520758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the dataset into train, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.583757Z",
     "start_time": "2020-06-17T17:03:26.552758Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = len(text_encoded) * 90 // 100 # keep 90% for training\n",
    "train = text_encoded[:train_size]\n",
    "test = text_encoded[-train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train an RNN we need to chop the long sequence of text into multiple windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.867756Z",
     "start_time": "2020-06-17T17:03:26.584757Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def windows(text, window_size = 100):\n",
    "    start_index = 0\n",
    "    end_index = len(text) - window_size\n",
    "    text_windows = []\n",
    "    while start_index < end_index:\n",
    "      text_windows.append(text[start_index:start_index+window_size+1])\n",
    "      start_index += 1\n",
    "    return text_windows\n",
    "\n",
    "text_windows = windows(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:26.899756Z",
     "start_time": "2020-06-17T17:03:26.868758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou ',\n",
       " 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou a',\n",
       " 'rst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou ar']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_windows[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:27.484148Z",
     "start_time": "2020-06-17T17:03:26.900759Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CharRNNDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, text_encoded_windows, train=True):\n",
    "    self.text = text_encoded_windows\n",
    "    self.train = train\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.text)\n",
    "\n",
    "  def __getitem__(self, ix):\n",
    "    if self.train:\n",
    "      return torch.tensor(self.text[ix][:-1]), torch.tensor(self.text[ix][-1])\n",
    "    return torch.tensor(self.text[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:30.266393Z",
     "start_time": "2020-06-17T17:03:27.485147Z"
    }
   },
   "outputs": [],
   "source": [
    "text_encoded_windows = windows(train)\n",
    "\n",
    "# get a small subset\n",
    "dataset = CharRNNDataset(text_encoded_windows[:20000])\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:30.314394Z",
     "start_time": "2020-06-17T17:03:30.267395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all r'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, output = dataset[10]\n",
    "tokenizer.seq_to_text(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:30.362395Z",
     "start_time": "2020-06-17T17:03:30.315395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.seq_to_text([output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each character is a category, we need to transform the inputs to either one-hot vectors or as embeddings. Here, we will use embeddings.\n",
    "\n",
    "An embedding is a trainable dense vector that represents a category. The number of dimensions of the embedding is a hyperparameter that can be tweaked. Since embeddings are trainable, they will improve during training grouping together similar categories. The better the representation, the easier it will be for the neural network to make accurate predictions. This is also called *representation learning*. When applied to NLP tasks, we generally talk about *word embeddings*, which can generate results such as \n",
    "\n",
    "![](https://blog.enzymeadvisinggroup.com/hs-fs/hubfs/Word%20Embeddings%20en%20el%20Natural%20Language%20Processing.png?width=1505&name=Word%20Embeddings%20en%20el%20Natural%20Language%20Processing.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:03:30.408396Z",
     "start_time": "2020-06-17T17:03:30.363395Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharRNN(torch.nn.Module):\n",
    "  def __init__(self, n_out=100, dropout=0.2, input_size=100, embedding_size=100, hidden_size=128):\n",
    "    super().__init__()\n",
    "    self.encoder = torch.nn.Embedding(input_size, embedding_size)\n",
    "    self.rnn = torch.nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=2, dropout=dropout, batch_first=True)\n",
    "    self.fc = torch.nn.Linear(hidden_size, n_out)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.encoder(x)\n",
    "    x, h = self.rnn(x)         \n",
    "    y = self.fc(x[:,-1,:])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:04:18.595170Z",
     "start_time": "2020-06-17T17:03:30.409395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Epoch 1/10 loss 2.72577<p>Epoch 2/10 loss 2.16700<p>Epoch 3/10 loss 1.97235<p>Epoch 4/10 loss 1.84173<p>Epoch 5/10 loss 1.74779<p>Epoch 6/10 loss 1.66670<p>Epoch 7/10 loss 1.60067<p>Epoch 8/10 loss 1.54893<p>Epoch 9/10 loss 1.48815<p>Epoch 10/10 loss 1.44920"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import CharRNNModel\n",
    "\n",
    "model = CharRNNModel(CharRNN())\n",
    "\n",
    "model.compile(optimizer = torch.optim.Adam(model.net.parameters()),\n",
    "              loss = torch.nn.CrossEntropyLoss())\n",
    "\n",
    "hist = model.fit(dataloader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:04:18.642173Z",
     "start_time": "2020-06-17T17:04:18.596176Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ge repose, to be asleep\\nWith eyes wide open; standing, speaking, moving,\\nAnd yet so fast asleep.\\n\\nANTONIO:\\nNoble Sebastian,\\nThou let'st thy fortune sleep--die, rather; wink'st\\nWhiles thou art waking.\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[-200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:04:18.689181Z",
     "start_time": "2020-06-17T17:04:18.643172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = \"With eyes wide open; standing, speaking, movin\"\n",
    "X_new_encoded = tokenizer.text_to_seq(X_new)\n",
    "y_pred = model.predict(X_new_encoded)\n",
    "y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
    "tokenizer.seq_to_text([y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start generating fake text. We could start with a seed and then recursively generate text, adding the new characters to the existing ones. This approach, however, results in repetitive text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:04:21.662871Z",
     "start_time": "2020-06-17T17:04:18.690184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With eyes wide open; standing, speaking, moving the poor poor most the poor poor most the poor poor most the poor poor poor most the poor poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most the poor most th'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = \"With eyes wide open; standing, speaking, movin\"\n",
    "\n",
    "for i in range(1000):\n",
    "  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n",
    "  y_pred = model.predict(X_new_encoded)\n",
    "  y_pred = torch.argmax(y_pred, axis=1)[0].item()\n",
    "  X_new += tokenizer.seq_to_text([y_pred])\n",
    "\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pick the next character randomly, with a probability equal to the estimated probability. This will generate more diverse and interesting text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:04:24.741951Z",
     "start_time": "2020-06-17T17:04:21.663874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With eyes wide open; standing, speaking, moving\n",
      "he veling to say\n",
      "You.\n",
      "\n",
      "First Citizen:\n",
      "No' me loved one well you are they swall no, the senators.\n",
      "\n",
      "All:\n",
      "Cond I a prow shalf the repome,\n",
      "Where shall and the did seven should if their are alpething\n",
      "hatine a the sen'd madam; the most forth belly shall the quuskery asice\n",
      "To proked for with he gods did the are to cour offite. Tull no plrasome that say it in plyut. He counsting but it, no tell sand not to the.\n",
      "\n",
      "Second Citizen:\n",
      "O, be pray loved well a dough reed, the shall you whish\n",
      "affering to kin of for the prou, give he felly shall\n",
      "As poor prettungry and Sepeationg make and me grainst to this a ganity\n",
      "To comand well muth at suskence that madam, mushints have reshigh of your tould his mablito\n",
      "kn one her midssuser diglad power himself aftelved.\n",
      "\n",
      "First Senater: Cominius\n",
      "Lets of must he hus, it madaus to that the shour but mie it him discused for receive his with arms.\n",
      "\n",
      "VALERIA:\n",
      "No, you was hem'st him; in madam\n",
      "The disconess rather is in the city.\n",
      "\n",
      "All:\n",
      "He carewell.\n",
      "\n",
      "Fiest Citizen:\n",
      "See the ma\n"
     ]
    }
   ],
   "source": [
    "X_new = \"With eyes wide open; standing, speaking, movin\"\n",
    "\n",
    "temp= 0.8\n",
    "for i in range(1000):\n",
    "  X_new_encoded = tokenizer.text_to_seq(X_new[-100:])\n",
    "  y_pred = model.predict(X_new_encoded)\n",
    "  y_pred = y_pred.view(-1).div(temp).exp()\n",
    "  top_i = torch.multinomial(y_pred, 1)[0]\n",
    "  predicted_char = tokenizer.all_characters[top_i]\n",
    "  X_new += predicted_char\n",
    "\n",
    "print(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built a character-level model, and now it's time to look at a word-level model to tackle a common NLP task: *sentiment analysis*. We will work with the IMDb review dataset, containing 50,000 movie reviews, to classify text into positive or negative reviews. This is also known as *text classification*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:24.579490Z",
     "start_time": "2020-06-17T17:04:24.744950Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "TEXT = torchtext.data.Field(tokenize = 'spacy')\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:24.642485Z",
     "start_time": "2020-06-17T17:05:24.580490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:24.704484Z",
     "start_time": "2020-06-17T17:05:24.643488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '\"', 'Teachers', '\"', '.', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', 'High', \"'s\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"', 'Teachers', '\"', '.', 'The', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'pomp', ',', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students', '.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High', '.', 'A', 'classic', 'line', ':', 'INSPECTOR', ':', 'I', \"'m\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', '.', 'STUDENT', ':', 'Welcome', 'to', 'Bromwell', 'High', '.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched', '.', 'What', 'a', 'pity', 'that', 'it', 'is', \"n't\", '!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:24.784485Z",
     "start_time": "2020-06-17T17:05:24.705493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data = train_data.split()\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we used a tokenizer in the previous section to assign a diferent label to each character, here we need to build a vocabulary where each word will be assigned a unique label. However, there are over 100,000 different words in the training set which can be problematic (specially if we are using one-hot encoding). An alternative is to keep to most frequent words and then replace the rest with an unkown token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.548503Z",
     "start_time": "2020-06-17T17:05:24.785491Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.612506Z",
     "start_time": "2020-06-17T17:05:25.549512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two extra tokens: *unk* and *pad*. The *pad* token is used to ensure that all the sentences have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.692502Z",
     "start_time": "2020-06-17T17:05:25.613504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 203562),\n",
       " (',', 193222),\n",
       " ('.', 166197),\n",
       " ('and', 110106),\n",
       " ('a', 110092),\n",
       " ('of', 101336),\n",
       " ('to', 94366),\n",
       " ('is', 76614),\n",
       " ('in', 61923),\n",
       " ('I', 54195)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.754500Z",
     "start_time": "2020-06-17T17:05:25.693509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.818501Z",
     "start_time": "2020-06-17T17:05:25.755503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'neg': 0, 'pos': 1})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.882503Z",
     "start_time": "2020-06-17T17:05:25.819504Z"
    }
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataloader = {\n",
    "    'train': torchtext.data.BucketIterator(train_data, batch_size=64, sort_within_batch=True, device=device),\n",
    "    'val': torchtext.data.BucketIterator(valid_data, batch_size=64, device=device),\n",
    "    'test': torchtext.data.BucketIterator(test_data, batch_size=64, device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:25.946507Z",
     "start_time": "2020-06-17T17:05:25.883507Z"
    }
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "  def __init__(self):\n",
    "    self.name = \"acc\"\n",
    "  \n",
    "  def call(self, outputs, targets):\n",
    "    rounded_preds = torch.round(torch.sigmoid(outputs))\n",
    "    correct = (rounded_preds == targets).float() \n",
    "    acc = correct.sum().item() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:05:26.007500Z",
     "start_time": "2020-06-17T17:05:25.947512Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [sent len, batch size]        \n",
    "        embedded = self.embedding(text)        \n",
    "        #embedded = [sent len, batch size, emb dim]        \n",
    "        output, hidden = self.rnn(embedded)        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        y = self.fc(output[-1,:,:].squeeze(0)).squeeze(1)     \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:07:07.660099Z",
     "start_time": "2020-06-17T17:05:26.008505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/5 loss 0.63174 acc 0.63098 val_loss 0.61144 val_acc 0.64176<p>Epoch 2/5 loss 0.35190 acc 0.84863 val_loss 0.35259 val_acc 0.84304<p>Epoch 3/5 loss 0.22103 acc 0.91362 val_loss 0.33939 val_acc 0.86294<p>Epoch 4/5 loss 0.13969 acc 0.94930 val_loss 0.29074 val_acc 0.88156<p>Epoch 5/5 loss 0.07854 acc 0.97314 val_loss 0.40770 val_acc 0.86795"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import WordModel\n",
    "\n",
    "model = WordModel(RNN(len(TEXT.vocab)))\n",
    "\n",
    "model.compile(optimizer = torch.optim.Adam(model.net.parameters()),\n",
    "              loss = torch.nn.BCEWithLogitsLoss(),\n",
    "              metrics=[Metric()])\n",
    "\n",
    "hist = model.fit(dataloader['train'], dataloader['val'], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:07:25.446168Z",
     "start_time": "2020-06-17T17:07:07.661099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "loss 0.40895 acc 0.86913"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(dataloader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell the network NOT to learn the pad token, since it is irrelevant. This is called *masking*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:07:25.509512Z",
     "start_time": "2020-06-17T17:07:25.447168Z"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedRNN(RNN):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=1, dropout=0.2, pad_idx=0):\n",
    "        super().__init__(input_dim, embedding_dim, hidden_dim, output_dim, dropout)\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:09:06.095105Z",
     "start_time": "2020-06-17T17:07:25.510513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/5 loss 0.61644 acc 0.64328 val_loss 0.67262 val_acc 0.71884<p>Epoch 2/5 loss 0.33657 acc 0.85672 val_loss 0.37607 val_acc 0.87646<p>Epoch 3/5 loss 0.21402 acc 0.91624 val_loss 0.28097 val_acc 0.89003<p>Epoch 4/5 loss 0.14486 acc 0.94644 val_loss 0.29253 val_acc 0.88484<p>Epoch 5/5 loss 0.08969 acc 0.96997 val_loss 0.31538 val_acc 0.88316"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WordModel(MaskedRNN(len(TEXT.vocab),pad_idx=TEXT.vocab.stoi[TEXT.pad_token]))\n",
    "\n",
    "model.compile(optimizer = torch.optim.Adam(model.net.parameters()),\n",
    "              loss = torch.nn.BCEWithLogitsLoss(),\n",
    "              metrics=[Metric()])\n",
    "\n",
    "hist = model.fit(dataloader['train'], dataloader['val'], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:09:23.239370Z",
     "start_time": "2020-06-17T17:09:06.096104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "loss 0.32365 acc 0.87864"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(dataloader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidireccional RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See other notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another powerful technique consists on using pretrained embeddings. Like this we are not starting from random embeddings, and using embeddings trained on bigger datasets can improve our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:09:24.201899Z",
     "start_time": "2020-06-17T17:09:23.240371Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:09:24.281896Z",
     "start_time": "2020-06-17T17:09:24.202901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8684,  0.7003, -0.0894,  ...,  0.5347,  0.7920,  1.2473],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 1.6995, -1.6918, -0.6325,  ..., -0.1663, -0.5969,  1.9689],\n",
      "        ...,\n",
      "        [-2.1874, -0.0277,  0.5850,  ...,  0.1656,  0.7396,  0.0213],\n",
      "        [-1.6543,  1.9068,  0.8589,  ...,  0.4353,  0.8982, -0.7845],\n",
      "        [ 1.1289, -0.5085,  0.8016,  ..., -1.1249, -0.4152,  0.2123]])\n"
     ]
    }
   ],
   "source": [
    "net = MaskedRNN(len(TEXT.vocab), embedding_dim=100, pad_idx=TEXT.vocab.stoi[TEXT.pad_token])\n",
    "\n",
    "print(net.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:09:24.345895Z",
     "start_time": "2020-06-17T17:09:24.282901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [ 0.5486,  0.4344,  0.6683,  ..., -1.5594, -0.0370,  0.4488],\n",
      "        [ 0.5242,  0.3242,  0.2375,  ..., -0.8456,  0.3121,  0.7025],\n",
      "        [-0.1778,  0.7499, -0.2611,  ..., -1.1254,  0.7422, -0.1340]])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "net.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "\n",
    "net.embedding.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(100)\n",
    "net.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)\n",
    "\n",
    "print(net.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:11:02.640222Z",
     "start_time": "2020-06-17T17:09:24.347895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/5 loss 0.54464 acc 0.70549 val_loss 1.31295 val_acc 0.56042<p>Epoch 2/5 loss 0.29384 acc 0.88381 val_loss 0.43743 val_acc 0.80301<p>Epoch 3/5 loss 0.19735 acc 0.92600 val_loss 0.27980 val_acc 0.89317<p>Epoch 4/5 loss 0.13211 acc 0.95525 val_loss 0.33316 val_acc 0.88444<p>Epoch 5/5 loss 0.08569 acc 0.97412 val_loss 0.38809 val_acc 0.89158"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WordModel(net)\n",
    "\n",
    "model.compile(optimizer = torch.optim.Adam(model.net.parameters()),\n",
    "              loss = torch.nn.BCEWithLogitsLoss(),\n",
    "              metrics=[Metric()])\n",
    "\n",
    "hist = model.fit(dataloader['train'], dataloader['val'], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:11:19.565831Z",
     "start_time": "2020-06-17T17:11:02.642223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "loss 0.39517 acc 0.88587"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(dataloader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our model to predict if a movie review is good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:11:20.036829Z",
     "start_time": "2020-06-17T17:11:19.566832Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:11:20.100829Z",
     "start_time": "2020-06-17T17:11:20.037829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0732, 0.9613, 0.8762, 0.0119], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
    "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
    "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
    "tensor = torch.tensor(indexed).to(device).permute(1,0)\n",
    "model.net.eval()\n",
    "prediction = torch.sigmoid(model.net(tensor))\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
