{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMGu0iFSUaH6"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/dl/blob/master/nlp/sentiment_analysis_bidirectional.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vIqkVLB1UaH6"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:45.628297Z",
     "start_time": "2020-06-17T17:22:46.214737Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZsO_rUghUaH7",
    "outputId": "dcd611ae-8eed-40dc-eee4-e2ff9f352d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:09<00:00, 9.22MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "TEXT = torchtext.data.Field(tokenize = 'spacy')\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.float)\n",
    "\n",
    "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:45.692295Z",
     "start_time": "2020-06-17T17:23:45.629298Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "alkN82qYUaH9",
    "outputId": "c92381a8-d060-4f6d-d171-36ca4e34d0b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:45.756297Z",
     "start_time": "2020-06-17T17:23:45.693297Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qe0nreH4UaIA",
    "outputId": "ee22a9de-ad4b-4d69-e01e-a9237633b633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Cinderella', 'In', 'my', 'opinion', 'greatest', 'love', 'story', 'ever', 'told', 'i', 'loved', 'it', 'as', 'a', 'kid', 'and', 'i', 'love', 'it', 'now', 'a', 'wonderful', 'Disney', 'masterpiece', 'this', 'is', '1', 'of', 'my', 'favorite', 'movies', 'i', 'love', 'Disney', '.', 'i', 'could', 'rave', 'on', 'and', 'on', 'about', 'Cinderella', 'and', 'Disney', 'all', 'day', 'but', 'i', 'wo', 'nt', 'i', 'll', 'give', 'you', 'a', 'brief', 'outline', 'of', 'the', 'story', '.', 'When', 'a', 'young', 'girl', \"'s\", 'father', 'dies', 'she', 'has', 'to', 'live', 'with', 'her', 'evil', 'step', 'mother', 'and', 'her', 'equally', 'ugly', 'and', 'nasty', 'step', 'sisters', 'Drusilla', 'and', 'Anastasia', '.', 'Made', 'to', 'do', 'remedial', 'house', 'chores', 'all', 'day', 'poor', 'Cinderella', 'has', 'only', 'the', 'little', 'mice', 'who', 'scurry', 'around', 'the', 'house', 'and', 'her', 'dog', 'Bruno', 'as', 'friends', '.', 'When', 'one', 'day', 'a', 'letter', 'is', 'sent', 'to', 'her', 'house', 'telling', 'all', 'available', 'women', 'to', 'attend', 'a', 'royal', 'ball', '.', 'Cinderellas', 'evil', 'step', 'mother', 'and', 'step', 'sisters', 'try', 'to', 'prevent', 'her', 'attendance', 'Cinderella', 'finally', 'gets', 'her', 'dream', 'and', 'wish', 'and', 'is', 'able', 'to', 'attend', 'her', 'captive', 'beauty', ',', 'Genorisity', 'and', 'beautiful', 'nature', 'help', 'her', 'win', 'her', 'prince', '.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:45.836297Z",
     "start_time": "2020-06-17T17:23:45.757297Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JT5r55K0UaIC",
    "outputId": "b14032fe-db73-47f8-cc10-6bfd2e285082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data = train_data.split()\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:46.836359Z",
     "start_time": "2020-06-17T17:23:45.837296Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RTZivX7fUaIE"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:46.884362Z",
     "start_time": "2020-06-17T17:23:46.837361Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sMzN5xN8UaIG",
    "outputId": "49e6d039-8f7e-42ba-f4b4-3a2dffde7052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zv9vrGiyUaII"
   },
   "source": [
    "We have two extra tokens: *unk* and *pad*. The *pad* token is used to ensure that all the sentences have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:46.963359Z",
     "start_time": "2020-06-17T17:23:46.885362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "IJyU8KFBUaIJ",
    "outputId": "3d224069-95ee-4f87-e690-b9fac264a052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 205359),\n",
       " (',', 194246),\n",
       " ('.', 166557),\n",
       " ('and', 110362),\n",
       " ('a', 110266),\n",
       " ('of', 102210),\n",
       " ('to', 94693),\n",
       " ('is', 76797),\n",
       " ('in', 61951),\n",
       " ('I', 54422)]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.026361Z",
     "start_time": "2020-06-17T17:23:46.965362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ruW9YxhuUaIK",
    "outputId": "1bd7da80-c52c-460e-a128-e60d5d7eefa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.090361Z",
     "start_time": "2020-06-17T17:23:47.028362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "h6NJ57EmUaIM",
    "outputId": "3ee7632b-41c2-4b30-a815-6e825b9fca06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
       "            {'neg': 1, 'pos': 0})"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.169361Z",
     "start_time": "2020-06-17T17:23:47.091362Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "-o8_AY2-UaIO"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataloader = {\n",
    "    'train': torchtext.data.BucketIterator(train_data, batch_size=64, sort_within_batch=True, device=device),\n",
    "    'val': torchtext.data.BucketIterator(valid_data, batch_size=64, device=device),\n",
    "    'test': torchtext.data.BucketIterator(test_data, batch_size=64, device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3sdfja7UaIT"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.230359Z",
     "start_time": "2020-06-17T17:23:47.170360Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "lpABo77TUaIT"
   },
   "outputs": [],
   "source": [
    "class Metric():\n",
    "  def __init__(self):\n",
    "    self.name = \"acc\"\n",
    "  \n",
    "  def call(self, outputs, targets):\n",
    "    rounded_preds = torch.round(torch.sigmoid(outputs))\n",
    "    correct = (rounded_preds == targets).float() \n",
    "    acc = correct.sum().item() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.294360Z",
     "start_time": "2020-06-17T17:23:47.231359Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WGobqzdWUaIV"
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=1, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #text = [sent len, batch size]        \n",
    "        embedded = self.embedding(text)        \n",
    "        #embedded = [sent len, batch size, emb dim]        \n",
    "        output, hidden = self.rnn(embedded)        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        y = self.fc(output[-1,:,:].squeeze(0)).squeeze(1)     \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uXyVVmvUaIW"
   },
   "source": [
    "We can tell the network NOT to learn the pad token, since it is irrelevant. This is called *masking*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.358359Z",
     "start_time": "2020-06-17T17:23:47.295359Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "R1hazaViUaIX"
   },
   "outputs": [],
   "source": [
    "class MaskedRNN(RNN):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=1, dropout=0.2, pad_idx=0):\n",
    "        super().__init__(input_dim, embedding_dim, hidden_dim, output_dim, dropout)\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "niIGUyjEUaIZ"
   },
   "source": [
    "### Bidireccional RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2bn0DxgUaIZ"
   },
   "source": [
    "At each time step, a regular recurrent layer only looks at past and present inputs before generating an output. This makes sense for time series forecasting, but for some NLP tasks it is preferable to look ahead at the next words before encoding a given word. We can achieve this using bidirectional recurrent layers.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/764/1*6QnPUSv_t9BY9Fv8_aLb-Q.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.596360Z",
     "start_time": "2020-06-17T17:23:47.359360Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "8qLK_ntMUaIa"
   },
   "outputs": [],
   "source": [
    "from src import WordModel\n",
    "\n",
    "class MaskedBidirectionalRNN(MaskedRNN):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=1, dropout=0.2, pad_idx=0, bidirectional=True):\n",
    "        super().__init__(input_dim, embedding_dim, hidden_dim, output_dim, dropout)\n",
    "        self.rnn = torch.nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=2, dropout=dropout, bidirectional=bidirectional)\n",
    "        if bidirectional:\n",
    "          self.fc = torch.nn.Linear(2*hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T17:23:47.676359Z",
     "start_time": "2020-06-17T17:23:47.597360Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MeEDXzJUUaId"
   },
   "outputs": [],
   "source": [
    "net = MaskedBidirectionalRNN(len(TEXT.vocab), embedding_dim=100, pad_idx=TEXT.vocab.stoi[TEXT.pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-17T17:22:46.377Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "colab_type": "code",
    "id": "HA71AvTrUaIg",
    "outputId": "bfba7479-a114-42f5-8790-5cd46b80b971"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Epoch 1/5 loss 0.65932 acc 0.59478 val_loss 0.76550 val_acc 0.51099<p>Epoch 2/5 loss 0.48434 acc 0.77391 val_loss 0.48038 val_acc 0.78037<p>Epoch 3/5 loss 0.30191 acc 0.87401 val_loss 0.31354 val_acc 0.86560<p>Epoch 4/5 loss 0.21232 acc 0.91704 val_loss 1.74227 val_acc 0.51695<p>Epoch 5/5 loss 0.15671 acc 0.94361 val_loss 0.30987 val_acc 0.87522"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = WordModel(net)\n",
    "\n",
    "model.compile(optimizer = torch.optim.Adam(model.net.parameters()),\n",
    "              loss = torch.nn.BCEWithLogitsLoss(),\n",
    "              metrics=[Metric()])\n",
    "\n",
    "hist = model.fit(dataloader['train'], dataloader['val'], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-17T17:22:46.378Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1PQpSrPwUaIk",
    "outputId": "00d50368-e1f7-4dbd-b075-9fd733980eaf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "loss 0.29945 acc 0.87844"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(dataloader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6mkVaipUaIl"
   },
   "source": [
    "We can now use our model to predict if a movie review is good or bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-17T17:22:46.406Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "aQATFA3EUaIl"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-06-17T17:22:46.408Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "enuEo0enUaIn",
    "outputId": "d586d091-54e5-4b55-e0f3-7dfe1ea61a8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9891, 0.0520, 0.0571, 0.9869], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
    "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
    "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
    "tensor = torch.tensor(indexed).to(device).permute(1,0)\n",
    "model.net.eval()\n",
    "prediction = torch.sigmoid(model.net(tensor))\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sentiment_analysis_bidirectional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
